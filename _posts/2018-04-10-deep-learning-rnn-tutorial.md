---
layout: post
title: 深度学习之循环神经网络
date: 2018-04-10 07:40:00
tags: [深度学习, 循环神经网络]
---

### 前言

循环神经网络RNN相对来说是一个很简单的网络结构, 网上也有大把的文章来介绍RNN到底是什么东西?RNN能干什么, 但是由于我一直纠结于RNN前一个节点的输出与后一个节点的输入应该以一种什么样的连接方式进行连接的问题一直不得要领, 窥不见RNN的真实面目. 通过昨天看Tensorflow的BasicRNNCell的源码实现才自认为是懂了一点RNN的基本原理与实现.


### RNN的定义

RNN循环神经网络能够记忆前一个输入的一些信息, 能够解决长期依赖问题：在语言模型、语音识别中需要根据上下文进行推断和预测，上下文的获取可以根据马尔科夫假设获取固定上下文。RNN可以通过中间状态保存上下文信息，作为输入影响下一时序的预测。当然也可以不用理会关于RNN的这些概念性质的东西. 

对于RNN结构的展开还是要介绍一下的, 虽然网上一大堆相关图片.

![RNN结构展开形状](/assets/images/2018-04-09-deeplearning-rnn-unfold.png)

将上图中的展开式表示成函数形式就是这个样子的

![RNN的函数表现](/assets/images/2018-04-09-deep-learning-rnn-math.png)

